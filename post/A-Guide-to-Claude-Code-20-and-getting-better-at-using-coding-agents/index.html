<!DOCTYPE html> <html lang="zh-CN" class="dark"> <head><meta charset="UTF-8"><link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="apple-mobile-web-app-title" content="2kindlebox"><meta name="msapplication-TileColor" content="#1e2030"><meta name="viewport" content="width=device-width,initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover"><meta name="description" content="28 Dec, 2025  https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/"><link rel="icon" href="/favicon.ico"><title>A Guide to Claude Code 2.0 and getting better at using coding agents | 2kindlebox</title><link rel="stylesheet" href="/_astro/_page_.Q94QMkaZ.css">
<style>.outlines a[data-anchor-tag=H1]{margin-left:0}.outlines a[data-anchor-tag=H2]{margin-left:12px}.outlines a[data-anchor-tag=H3]{margin-left:24px}.outlines a[data-anchor-tag=H4]{margin-left:36px}.outlines a[data-anchor-tag=H5]{margin-left:48px}.outlines a[data-anchor-tag=H6]{margin-left:60px}
._tabset_selm3_1 ._tab-panel_selm3_1{display:none}._tabset_selm3_1 ._tab-panels_selm3_4{display:flex}._tabset_selm3_1 input[data-tab-name=direct]{display:none}._tabset_selm3_1 input[data-tab-name=direct]:checked~._tab-panels_selm3_4 ._tab-panel_selm3_1[data-tab-name=direct]{display:block}._tabset_selm3_1 input[data-tab-name=direct]:checked~._tab-labels_selm3_13 label[data-tab-name=direct]{border-bottom:2px solid red}._tabset_selm3_1 input[data-tab-name=app]{display:none}._tabset_selm3_1 input[data-tab-name=app]:checked~._tab-panels_selm3_4 ._tab-panel_selm3_1[data-tab-name=app]{display:block}._tabset_selm3_1 input[data-tab-name=app]:checked~._tab-labels_selm3_13 label[data-tab-name=app]{border-bottom:2px solid red}
</style>
<link rel="stylesheet" href="/_astro/_page_.ypUYv9mY.css">
<link rel="stylesheet" href="/_astro/_id_.CdoHgwyN.css"><script type="module" src="/_astro/hoisted.BrQ9zIQK.js"></script></head> <body class="min-h-screen"> <header class="flex justify-between items-center px-4 py-3 border-b" style="border-color: #292e42;"> <a href="/" class="text-lg font-semibold tracking-tight hover:opacity-80 transition-opacity" style="color: #c8d3f5;"> 2kindlebox </a> <div class="flex items-center gap-3">   <div id="auth"></div> </div> </header>  <main> <div class="content"> <div class="w-full flex gap-2 pb-2">  <a href="/tag/ai" class="rounded hover:bg-gray-200 dark:hover:bg-modal px-3 py-1 cursor-pointer">
#ai </a><a href="/tag/Agentic%20Engineering" class="rounded hover:bg-gray-200 dark:hover:bg-modal px-3 py-1 cursor-pointer">
#Agentic Engineering </a><a href="/tag/aiskills" class="rounded hover:bg-gray-200 dark:hover:bg-modal px-3 py-1 cursor-pointer">
#aiskills </a> </div> <div class="ud-root read-only flex-1"><h1 level="1" id="A-Guide-to-Claude-Code-20-and-getting-better-at-using-coding-agents">A Guide to Claude Code 2.0 and getting better at using coding agents</h1><p><em>28 Dec, 2025  </em><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/"><em>https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/</em></a></p><h2 level="2" id="Table-of-Contents">Table of Contents</h2><ol><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#intro">Intro</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#why-i-wrote-this-post">Why I wrote this post</a></p><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#the-map-is-not-the-territory">The Map is not the territory</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#this-post-will-help-you-keep-up-in-general">This post will help you keep up in general</a></p></li></ul></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#lore-time---my-love-and-hate-relationship-with-anthropic-and-how-i-reconciled-with-claude-hint-opus-45">Lore time - My Love and Hate relationship with Anthropic</a></p><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#timeline">Timeline</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#my-codex-era">My Codex era</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#anthropic-redemption-arc--regaining-mandate-of-heaven">Anthropic Redemption Arc + Regaining mandate of heaven</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#why-opus-45-feels-goooood">Why Opus 4.5 feels goooood</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#this-post-is-not-sponsored">This post is not sponsored</a></p></li></ul></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#pointers-for-the-technically-lite">Pointers for the technically-lite</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#the-evolution-of-claude-code">The Evolution of Claude Code</a></p><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#quality-of-life-improvements-in-cc-20">Quality of life improvements in CC 2.0</a></p></li></ul></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#feature-deep-dive">Feature Deep Dive</a></p><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#commands">Commands</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#sub-agents">Sub-agents</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#do-sub-agents-inherit-the-context">Do sub-agents inherit the context?</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#how-do-sub-agents-spawn">How do sub-agents spawn</a></p></li></ul></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#my-workflow">My Workflow</a></p><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#setup">Setup</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#exploration-and-execution">Exploration and Execution</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#what-i-use-and-dont">What I use (and don&apos;t)</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#review">Review</a></p></li></ul></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#intermission">Intermission</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#but-what-is-context-engineering">But what is Context Engineering</a></p><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#agents-are-token-guzzlers">Agents are token guzzlers</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#context-engineering">Context engineering</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#mcp-server-and-code-execution">MCP server and code execution</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#what-are-the-system-reminders-in-claude-prompts">What are the system-reminders in Claude prompts</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#skills">Skills</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#hooks">Hooks</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#combining-hooks-skills-and-reminders">Combining Hooks, Skills and Reminders</a></p></li></ul></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#conclusion">Conclusion</a></p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/#references">References</a></p></li></ol><hr><h2 level="2" id="Intro">Intro</h2><p>&lt;system-reminder&gt;</p><p>This post is a follow-up to my post from July&apos;25 - <a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-claude-code-experience-after-2-weeks-of-usage/">My Experience With Claude Code After 2 Weeks of Adventures</a>. If you are new to Claude Code or just want a quick refresh, I am once again asking you to go through it. It covers some lore, my workflow back then and then 80-90% of the Claude Code standard workflow. You may choose to skip the intro although I recommend you read it. Lore is important man.</p><p>A short recap - we had covered CLAUDE.md, scratchpad, using task tool (now sub-agents), the general plan + execute workflow, tips for context window management, Sonnet 4 vs Opus 4 (not relevant now), using shortcuts like <code>!</code> and using <code>Shift + ?</code> to show shortcuts, memory basics, <code>/resume</code> to restart conversation and short discussion on custom commands.</p><p>&lt;/system-reminder&gt;</p><h2 level="2" id="Why-I-wrote-this-post">Why I wrote this post</h2><p>I got a great response on my Opus 4.5 vibe-check tweets and still recieving good feedback on my July blog post (despite being somewhat poorly written). This shows there&apos;s clearly a demand for in-depth resources around Claude Code.</p><p>I noticed that lots of people, both technical and many non-technical or less hands-on people i.e <strong>technically-lite</strong> people have started to try Claude Code (CC). CC is more of a general agent - you can use it for tasks other than coding as well - like making an excel invoice, data analysis, errands on your machine etc. And of course everything I talk about is by default meant for coding too.</p><p></p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/12pm.webp" alt="Screenshot 2025-12-28 at 8"><p>Karpathy sensei captured the essence of a general agent beautifully way in his <a target="_blank" rel="noopener noreferrer" href="https://x.com/karpathy/status/2002118205729562949?s=20">2025 LLM in a review</a> article - &quot;it&apos;s a little spirit/ghost that &quot;lives&quot; on your computer.&quot;</p><p>If you can learn even 3-4 ideas that help you with using Claude Code (or other tools like Codex/Gemini CLI/OpenCode) or improve your understanding of LLMs, it would be a win for me.</p><h3 level="3" id="The-Map-is-not-the-territory">The Map is not the territory</h3><p>I don&apos;t want this post to be a prescription (map). My objective is to show you what is possible and the thought processes and simple things you can keep in mind to get the most out of these tools. I want to show you the map but also the territory.</p><p>Claude Code dominated the CLI coding product experience this year and all the CLI products like Codex, OpenCode, Amp CLI, Vibe CLI and even Cursor have heavily taken inspiration from it. <strong>This means learning how things work in Claude Code directly transfers to other tools both in terms of personal usage and production grade engineering.</strong></p><h3 level="3" id="This-post-will-help-you-keep-up-in-general">This post will help you keep up in general</h3><p>Karpathy sensei posted this which broke the Twitter timeline. This led to a lot of discussion and there were some really good takes - some which I have written about too.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/15am.webp" alt="Karpathy tweet about keeping up"><p>Karpathy sensei seen crashing out. <a target="_blank" rel="noopener noreferrer" href="https://x.com/karpathy/status/2004607146781278521?s=20">source</a></p><p>It&apos;s a reasonable crashout - the technology is evolving at a mindblowing pace and it&apos;s difficult to keep up for most of us and especially for senior folks and people with high quality standards. Nevertheless, I think if you are reading this post, it&apos;s scary but also exciting time to build stuff at speeds never possible before.</p><p>Instead of thinking in terms of &quot;keeping up&quot;, a better framing is how can I improve myself with help of these tools i.e augment.</p><p>In my opinion, there are 3 components to augment yourself:</p><ol><li><p><strong>Stay updated with tooling</strong> - What Karpathy sensei mentioned. Use these tools regularly and keep up with releases. I have been doing this regularly; it can be draining but I enjoy the process and I have the incentive that it helps me at my job. For the technically lite, even weekly/monthly updates would help.</p></li><li><p><strong>Upskill in your domain</strong> - It&apos;s a great time to spread both vertically (domain depth) and horizontally (adjacent areas). The more you know, the better you can prompt - converting unknown unknowns to known unknowns. Experience builds judgement and taste - that&apos;s what differentiates professional devs from vibe-coders. <strong>Since implementation is much faster now, you can spend more time on taste refinement.</strong></p></li></ol><p>For software engineering folks, this might mean getting better at good practices, system design, planning - where more thinking is involved. Ask more questions, run more experiments (since you can iterate fast), spend more time on understanding requirements. Using good software engineering practices to create better feedback loops for LLMs (good naming, refactoring, docs, tests, typed annotations, observability etc.). Please don&apos;t forget to come back to my post lol but I liked Addy Osmani&apos;s <a target="_blank" rel="noopener noreferrer" href="https://x.com/addyosmani/status/2004663973912932625?s=20">take</a> on this.</p><p>The idea is to let the LLM perform things with input, get output and see errors.</p><p>As an aside, getting better at articulating thoughts via writing helps. One may also try touch typing/writing using speech-to-text tools to operate faster.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/19am-3.webp" alt="bcherny discussion on prompting"><p>Boris on how domain knowledge leads to better execution with LLMs. Better judgement helps find shorter paths, acting as a multiplier. <a target="_blank" rel="noopener noreferrer" href="https://x.com/bcherny/status/2004626064187031831?s=20">source</a></p><ol start="3"><li><p><strong>Play more and have an open mind</strong> - Try out more models, especially SoTA ones. Don&apos;t be stingy. Ask questions, try asking the models to do tasks, even ones you think it can&apos;t do. You will be surprised... Once you do this enough, you develop an intuition.</p></li></ol><p>This post will act as a guide for things Karpathy said but you&apos;ll need to play around, build intuition and achieve outcomes with help of these tools yourself. The good news is it&apos;s fun.</p><p>âœ± Ruminating...</p><h2 level="2" id="Lore-time---My-Love-and-Hate-relationship-with-Anthropic-and-how-I-reconciled-with-Claude-hint-Opus-45">Lore time - My Love and Hate relationship with Anthropic and how I reconciled with Claude (hint: Opus 4.5)</h2><p>I am having a great time with Claude Code 2.0 since the launch of Opus 4.5 and it&apos;s been my daily driver since then. Before we go all lovey-dovey about Claude, I wanted to quickly go through the timeline and lore. I love yapping in my blog and I feel it&apos;s important to set the context here.</p><h3 level="3" id="Timeline">Timeline</h3><p>2025 saw release of many frontier models by OpenAI and Anthropic. Also, it&apos;s super under-talked but OpenAI actually caught up to Anthropic in code-generation capability - intelligence wise, context window effectiveness, instruction following and intent detection.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/21am-2.webp" alt="2025 AI Model Timeline"><p>2025 OpenAI and Anthropic release timeline</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/56pm.webp" alt="2025 AI Model Timeline"><p>been less than 45 days since opus 4.5 launch as we are speaking</p><p>It&apos;s been a wild year and honestly speaking I got tired of trying out new releases by OpenAI every 2 weeks.</p><blockquote><p>&gt;no swe-bench-verified comparison<br>&gt;no comparison against opus 4.5<br>&gt;&quot;we are topping in cybersecurity&quot;<br>&gt;mfw i realise i am the fucking eval <a target="_blank" rel="noopener noreferrer" href="https://t.co/4oDG3yj6CP">https://t.co/4oDG3yj6CP</a> <a target="_blank" rel="noopener noreferrer" href="https://t.co/aUfJfwROCf">pic.twitter.com/aUfJfwROCf</a></p><p>â€” sankalp (@dejavucoder) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/dejavucoder/status/2001734765289050567?ref_src=twsrc%5Etfw">December 18, 2025</a></p></blockquote><p>when i realise i am being the eval</p><p>There have been several Open Source competitors like GLM-4.7, Kimi-K2, Minimax-2.1. The space is very competitive and there is definitely an audience that uses the cheaper priced but high performant Chinese models for low-medium difficulty tasks.</p><p>That said, I still think Anthropic/OpenAI lead over Chinese Frontier models. The latter have contributed more in terms of open-sourcing techniques like in the DeepSeek R1 paper and Kimi K2 paper earlier in the year.</p><p>(Note: I am talking with respect to personal coding usage, not production API usage for applications).</p><h3 level="3" id="Lore-time">Lore time</h3><h4 level="4" id="Friendship-over-with-Claude-Now-Codex-is-my-best-friendo">Friendship over with Claude, Now Codex is my best friendo</h4><p>I was using Claude Code as my main driver from late June to early September. I cancelled my Claude Max (100 USD/month) sub in early September and switched to using OpenAI Codex as my main driver. Switch was driven by two factors -</p><ol><li><p>I didn&apos;t particularly like Sonnet 4/Opus 4 and GPT-5-codex was working at par with Sonnet 4.5 and wrote much better code. More reasoning -</p></li></ol><blockquote><p>claude code is more enjoyable as a product and has more features. i have always felt to try out more things related to automation in cc as compared to codex. once they drop a new iteration i would consider getting a max sub again if its better than gpt-5-codex</p><p>â€” sankalp (@dejavucoder) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/dejavucoder/status/1970110644478439889?ref_src=twsrc%5Etfw">September 22, 2025</a></p></blockquote><p>my reasoning for switching</p><p>Anthropic also had tonne of API outages and at one point of time they had degradation due to inference bugs. This also was a major driver for several people to move to the next best alternative i.e Codex or GPT-5.1 on Cursor.</p><ol start="2"><li><p>I had more system design and thinking work in September because of which Claude Max plan (100 USD one) was not a good deal. Codex provided a tonne of value for just 20 USD/month subscription and I almost never got rate-limited. Additionally, the codex devs are generous with resetting usage limits whenever they push bugs lol.</p></li></ol><h3 level="3" id="My-Codex-era">My Codex era</h3><p>I was using Codex (main driver) and Cursor (never cancelled) until late October. Claude Sonnet 4.5 had released on 29th September along with Claude Code 2.0.. and I did take a 20 USD sub from another email account of mine to try it out (I had lots of prompting work and Claude models are my preferred choice) but GPT-5/GPT-5-codex were overall better despite being slow.</p><p>Sonnet 4.5&apos;s problem was fast and good but it would make many haphazard changes which would lead to bugs for me. In other words, I felt it to be producing a lot of slop in comparison to GPT-5.1/GPT-5.1-codex later.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/06am.webp" alt="Sonnet 4.5 slop"><p>Sonnet 4.5 slop era</p><h3 level="3" id="Anthropic-Redemption-Arc--Regaining-mandate-of-heaven">Anthropic Redemption Arc + Regaining mandate of heaven</h3><p>Around October 30, Anthropic sent an email saying we are offering the 200 USD max plan to users who cancelled the subscription and obviously I took it.</p><blockquote><p>chat please remind me to cancel after 28 daysðŸ˜‚ <a target="_blank" rel="noopener noreferrer" href="https://t.co/TSGidVJ2xo">pic.twitter.com/TSGidVJ2xo</a></p><p>â€” sankalp (@dejavucoder) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/dejavucoder/status/1983606411411267960?ref_src=twsrc%5Etfw">October 29, 2025</a></p></blockquote><p>taking the Max plan offer</p><p>My Claude Code usage was still minimal but on 24th November, they launched Opus 4.5 and I had 5 days to try out Opus 4.5. I used the hell out of it for my work and also wrote this highly technical <a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/how-prompt-caching-works/">blog</a> with the help of it discovering several of its capabilities.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/42pm.webp" alt="Opus 4.5 enjoyment tweet"><p>Why I love Opus 4.5 and reasons to switch. <a target="_blank" rel="noopener noreferrer" href="https://x.com/dejavucoder/status/1996207749382987966">source</a></p><p>I had done a similar tweet when I had switched to GPT-5.1 which had gotten half the response of this one. This indicated to me that more people resonated with Opus 4.5 (at least on Twitter) back then. Also, many people were just not able to realise GPT-5.1&apos;s capabilities tbh.</p><p>Other than the above State of the Art at the coding benchmarks like SWE-bench-verified (code-generation), Tau Bench (agentic stuff), Opus 4.5 was faster, at-par in coding, super collaborative and good at communication. These factors led to my conversion. It had good vibes. More comparison points later in the post.</p><h3 level="3" id="Why-Opus-45-feels-goooood">Why Opus 4.5 feels goooood</h3><p>As I described in the screenshot, Opus 4.5 was roughly at same code-gen capability with GPT-5.1-Codex-Max.</p><p>Today, in my experience I think GPT-5.2-Codex exceeds Opus 4.5 in raw capability by a small margin. Still, Opus 4.5 has been my main driver since release.</p><p>I think first reason is it&apos;s faster and can do similar difficulty tasks in much lesser time than Codex. Also, it&apos;s overall a much better communicator and pair-programmer than Codex which can even ignore your instructions at times (and go and make changes). Opus has better intent-detection as well.</p><blockquote><p>One nice-use case shown <a target="_blank" rel="noopener noreferrer" href="https://x.com/trq212/status/2004575715472388278?s=20">here</a> by Thariq on creating a background async agent to explain changes to a non-technical person leveraging Claude&apos;s explanation abilities.</p></blockquote><p>To further demonstrate the difference, here&apos;s a CC vs Codex comparison</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/08am-2.webp" alt="Claude Code output"><p>Claude</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/22am.webp" alt="Codex output"><p>Codex. global verbosity set to high in .codex/config.toml. Thanks <a target="_blank" rel="noopener noreferrer" href="https://x.com/tokenbender">tokenbender</a>. More Codex config options <a target="_blank" rel="noopener noreferrer" href="https://developers.openai.com/codex/local-config/">here</a>.</p><p>For the same prompt, see the outputs. Codex is still a bit more concise while Claude matches my expectation. (It&apos;s worth mentioning that you can get Codex to write in more detail by adding something like reveal your thoughts in detail)</p><p>Codex always writes in nested bullets. Claude has a more conversational tone.</p><p>Another thing I want to highlight is the UI - Claude uses higher contrast text with bolder font weight, whereas Codex&apos;s text appears thinner and harder to read, with thinking traces shown in an even lighter shade which I find straining.</p><p><strong>Because of being faster not only in terms of lesser thinking to perform task but throughput wise also, it unlocks much faster feedback loops for your tasks. This makes progress feel more visceral</strong> even though capability wise, GPT-5.1/Codex were at par even in November. The only downside with faster loop is if you are cautious, you end up micro-managing for long hours.</p><p>Opus 4.5 is a great writer and comes closest to humans so I have always preferred Claude models for customizing prompts.</p><p>I don&apos;t claim this but many people love Claude Opus 4.5 for it&apos;s personality and the way it talks - some referring to it as Opus 4.5 having soul. This trait was somewhat lesser in Sonnet 3.7, Sonnet 4, Opus 4, Opus 4.1 but it came back in Opus 4.5. Amanda Askell post-trained the soul into Claude haha.</p><blockquote><p>I just want to confirm that this is based on a real document and we did train Claude on it, including in SL. It&apos;s something I&apos;ve been working on for a while, but it&apos;s still being iterated on and we intend to release the full version and more details soon. <a target="_blank" rel="noopener noreferrer" href="https://t.co/QjeJS9b3Gp">https://t.co/QjeJS9b3Gp</a></p><p>â€” Amanda Askell (@AmandaAskell) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/AmandaAskell/status/1995610567923695633?ref_src=twsrc%5Etfw">December 1, 2025</a></p></blockquote><p>Besides the model, obviously the Claude Code Product goes a long way to make things magical.</p><h4 level="4" id="Claude-Code-product-sparks-joy">Claude Code product sparks joy</h4><p>As a product it&apos;s a mile ahead of Codex in QoL features. The harness, prompts and the model make for a magical experience. The model is amazing but there is a massive amount of tasteful engineering that has gone into UX/UI and just the code/prompts to let Claude feel comfortable in the harness and make function calling accurate. We will explore this more in later sections.</p><h3 level="3" id="This-post-is-not-sponsored">This post is not sponsored</h3><p>Before we move ahead - my previous post somehow reached Hackernews #5 and I was facing allegations that my post was sponsored by Anthropic. I was like bro are you serious? Anthropic doesn&apos;t sponsor random users like me. Anthropic doesn&apos;t even think about me (meme.jpeg) besides from a user point of view.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/57am.webp" alt="Anthropic prompt caching prices"><p>Anthropic prompt caching prices, <a target="_blank" rel="noopener noreferrer" href="https://x.com/dejavucoder/status/1990513414926749881?s=20">source</a></p><p>Besides praise, I have been snarky, made fun of outages, made a lot of fun of Sonnet 4.5 slop. I have expressed what I have felt over time and it&apos;s led to good discourse on the timeline as well.</p><p>All this said, Claude Code has been one of the most enjoyable product experiences I have ever had. I am grateful and highly respect the engineering and research team behind it.</p><p>That&apos;s enough yapping. In the next few sections, I will talk about useful features that I didn&apos;t talk about in my previous blog and notable features introduced in the iterations from Claude 2.0 - 2.0.74.</p><h2 level="2" id="Pointers-for-the-technically-lite">Pointers for the technically-lite</h2><blockquote><p>currently using Claude Code for the first time, I can officially put &quot;Technical-lite&quot; on my resume now</p><p>â€” spor (@sporadica) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/sporadica/status/1999209309994090769?ref_src=twsrc%5Etfw">December 11, 2025</a></p></blockquote><p>shoutout to the technical-lite gang</p><p>I am assuming several technical-lite people are gonna read this. Few concepts to help comprehension later in the blog -</p><ol><li><p><strong>Context and Context window</strong> - Context refers to the input provided to the LLMs. This is usually text but nowadays models support image, audio, video.</p><p>More specifically, context is the input tokens. <strong>The context window refers to the maximum amount of tokens that an LLM can see and process at once</strong> during a conversation. It&apos;s like the model&apos;s working memory. Opus 4.5 has a 200K context window which is approximately 150,000 words.</p></li><li><p><strong>Tool calling</strong> - Learn about tool calling. Here&apos;s a good <a target="_blank" rel="noopener noreferrer" href="https://cursor.com/learn/tool-calling">resource</a>. You know that LLMs can generate text but what if you want the LLM to perform an action - say draft an email or lookup the weather on the internet or just do google search. That&apos;s where <code>tools</code> come in. <strong>Tools are functions defined by the engineer</strong> that do these exact things. We define tools and we let the LLM know about it in the system prompt and it can decide which <code>tool</code> to call when you are chatting with it! Once the tool call i.e the action is performed, the results are relayed back to the LLM.</p></li><li><p><strong>Agent</strong> - The simplest definition is <strong>an LLM that can pro-actively run tools to achieve a goal</strong>. For a more sophisticated definition, I like the one by Anthropic: &quot;Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.&quot; from <a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/building-effective-agents">Building Effective Agents</a>.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/agent.webp" alt="Agent loop diagram"><p>Source: <a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/building-effective-agents">Building Effective Agents</a></p></li><li><p><strong>&quot;Agentic&quot;</strong> - refers to the tool calling capabilities of the model - how pro-active, how accurate the tool calling is (detecting user&apos;s intent to perform the action, choosing the correct tool, knowing when to stop)</p></li><li><p><strong>Harness/scaffolding</strong> - Sonnet 4.5/Opus 4.5 are the models. They need to be provided with lots of &quot;scaffolding&quot; / layers of code, prompts, tool calls and software packaging/environment to make them work in a semi-autonomous fashion. Note that <strong>Claude Code is not a harness, it&apos;s a product</strong> (think the TUI, integrations etc.). Claude Code has a harness.</p></li></ol><p>âœ± Processing...</p><h2 level="2" id="The-Evolution-of-Claude-Code">The Evolution of Claude Code</h2><p>Claude Code has had lots of AI features and quality of life improvements since July. Let&apos;s look at the ones that I found to be useful. You can see all changes in the <a target="_blank" rel="noopener noreferrer" href="https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md">Changelog</a>.</p><h3 level="3" id="Quality-of-life-improvements-in-CC-20">Quality of life improvements in CC 2.0</h3><ol><li><p><strong>Syntax highlighting</strong> was recently added in 2.0.71. I spend 80% of the time in Claude Code CLI so this change has been a delight to me. I like to review most of the stuff once in Claude Code. Besides Opus 4.5 being really good, this feature has been quite a contributor for me not opening Cursor at all to review code.</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/28am.webp" alt="Claude Code syntax highlighting"><p>Claude Code syntax highlighting in diff</p><ol start="2"><li><p><strong>Tips</strong> - I have learnt a lot from these although this particular tip doesn&apos;t work for me xD</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/13am.webp" alt="Tips"><p>Tips shown when Claude is thinking</p><ol start="3"><li><p><strong>Feedback UI</strong> - This way of asking feedback is pretty elegant. It&apos;s been there for some time now. It pops up occasionally and you can quickly respond with a number key (1: Bad, 2: Fine, 3: Good) or dismiss with 0. I like the non-intrusive nature of it.</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/58am.webp" alt="Feedback UI"><p>in-session feedback prompt</p><ol start="4"><li><p><strong>Ask mode options</strong> - Another thing I like is Option 3 when it asks questions in the syntax highlighting image above - &quot;Type here to tell Claude what to do differently&quot;. Fun fact: All these are really prompts for the model whose output is parsed by another tool call and shown in this way.</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/59am.webp" alt="Ask mode options"><p>third option in ask mode</p><ol start="5"><li><p><strong>Ultrathink</strong> - I like to spam ultrathink for hard tasks or when I want Opus 4.5 to be more rigorous e.g. explaining me something, self-reviewing its changes</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/19am-2.webp" alt="ultrathink"><p>love the ultrathink color detail</p><ol start="6"><li><p><strong>Thinking toggle</strong> - Tab to toggle thinking on/off was a good feature. They changed it to Alt/Option + Tab recently but there&apos;s a bug and it does not work on Mac. Anyways CC defaults to thinking always true if you check in your <code>settings.json</code></p></li><li><p><code>/context</code> - Use <code>/context</code> to see current context usage. I tend to use this quite a bit. I would do a handoff or compact when I reach total 60% if building something complex.</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/55am.webp" alt="context usage"><p>context usage</p><ol start="8"><li><p><code>/usage</code><strong> and </strong><code>/stats</code> - Use <code>/usage</code> to see usage and <code>/stats</code> for stats. I don&apos;t use these as often.</p></li></ol><h4 level="4" id="Checkpointing-is-here">Checkpointing is here!</h4><ol start="9"><li><p><strong>Checkpointing</strong> - <code>Esc</code> + <code>Esc</code> or <code>/rewind</code> option now allows you to go back to a particular checkpoint like you could do in Cursor. It can rewind the code and conversation both. Doc <a target="_blank" rel="noopener noreferrer" href="https://code.claude.com/docs/en/checkpointing">link</a>. This was a major feature request for me.</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/43am.webp" alt="Checkpointing"><p>Esc + Esc fast or /rewind</p><ol start="10"><li><p><strong>Prompt suggestions</strong> (2.0.73) - <a target="_blank" rel="noopener noreferrer" href="https://x.com/claudeai/status/2001010062769434785?s=20">Prompt suggestions</a> are a recent addition and predictions are pretty decent. Claude Code is a token guzzler machine atp. Probably the simplest <a target="_blank" rel="noopener noreferrer" href="https://github.com/Piebald-AI/claude-code-system-prompts/blob/2d86000c62b6c7f119dbf086ab6932f13ebde0b8/system-prompts/agent-prompt-prompt-suggestion-generator-v2.md?plain=1#L4">prompt</a> I have seen.</p></li><li><p><strong>Prompt history search</strong> - Search through prompts using <code>Ctrl + R</code> (similar to terminal backsearch). I have it in 2.0.74. It can search across project wide conversations. Repeatedly do <code>Ctrl + R</code> to cycle through results.</p></li></ol><p>prompt suggestions and history search in action</p><ol start="12"><li><p><strong>Cursor cycling</strong> - When you reach beginning/end of prompt, press down/up to cycle around</p></li></ol><p>cursor cycling at prompt boundaries</p><ol start="13"><li><p><strong>Message queue navigation</strong> - It&apos;s possible to navigate through queued messages and image attachments (2.0.73) now (idk if it&apos;s possible to display image attachment as well).</p></li><li><p><strong>Fuzzy file search</strong> - File suggestion is 3x faster and supports fuzzy search (2.0.72)</p></li><li><p><strong>LSP support</strong> was added recently. Access via plugins.</p></li></ol><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/47am.webp" alt="LSP support"><p>LSP plugin</p><hr><p>There have been new integrations too like Slack Integration, Claude Web (beta), Claude Chrome extension. These are pretty obvious and I won&apos;t cover these. I think Claude Web would be interesting for many particularly (since you can launch tasks from iOS/Android too).</p><p>âœ± Synthesizing...</p><h2 level="2" id="Feature-Deep-Dive">Feature Deep Dive</h2><p>Next few sub-sections are all about most used features.</p><h3 level="3" id="Commands">Commands</h3><p>I didn&apos;t cover commands properly in my previous blog post. You can use <code>/</code> to access the built-in slash commands. These are pre-defined prompts that perform a specific task.</p><p>If these don&apos;t cover a specific task you want, then you can create a custom command. <strong>When you enter a command, that prompt gets appended to the current conversation/context and the main agent begins to perform the task.</strong></p><p>Commands can be made on a project level or global level. Project level resides at <code>.claude/commands/</code> and global one at <code>~/.claude/commands</code>.</p><p>Often when the context window starts getting full or I feel the model is struggling with a complex task, I want to start a new conversation using <code>/clear</code>. Claude provides <code>/compact</code> which also runs faster in CC 2.0 but sometimes I prefer to make Claude write what happened in current session (with some specific stuff) before I kill it and start a new one. I made a <code>/handoff</code> command for this.</p><p>If you find yourself writing a prompt for something repetitively and instructions can be static/precise, it&apos;s a good idea to make a custom command. You can tell Claude to make custom commands. It knows how (or it will search the web and figure it out via <a target="_blank" rel="noopener noreferrer" href="https://code.claude.com/docs/en/claude_code_docs_map.md">claude-code-guide.md</a>) and then it will make it for you.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/17am.webp" alt="Custom command"><p>making a custom command by telling Claude</p><p>You can find a bunch of commands, hooks, skills at <a target="_blank" rel="noopener noreferrer" href="https://github.com/hesreallyhim/awesome-claude-code?tab=readme-ov-file#slash-commands-">awesome-claude-code</a> though I recommend building your own or searching only when needed.</p><p>I have a command called <code>bootstrap-repo</code> that searches the repo with 10 parallel sub-agents to create a comprehensive doc. I rarely use it these days and so many parallel sub-agents lead to the Claude Code flickering bug lol.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/49am.webp" alt="Bootstrap repo"><p>Notice the Explore sub-agents running in parallel and the &quot;running in background&quot; status</p><p>Anyways, notice the &quot;Explore&quot; sub-agent and &quot;running in background&quot;.</p><h3 level="3" id="Sub-agents">Sub-agents</h3><p>Sub-agents were introduced shortly after my last post. They are separate Claude instances spawned by the main agent either on its own judgement or when you tell it to do so. These powers are already there in the system prompt (at least for the pre-defined ones like Explore); sometimes you just need to nudge Claude to use them. Understanding how they work helps when you need to micro-manage.</p><p>You can also define your custom sub-agents. To create one:</p><ol><li><p>Create a markdown file at <code>.claude/agents/your-agent-name.md</code></p></li><li><p>Specify the agent&apos;s name, instructions, and allowed tools</p></li></ol><p>Or just use <code>/agents</code> to manage and create sub-agents automatically - recommended approach.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/40am.webp" alt="Explore sub-agent"><p>how sub-agents are created by the main agent (Opus 4.5) via the Task tool</p><h4 level="4" id="Explore">Explore</h4><p>The &quot;Explore&quot; thing in above pic is a sub-agent. You can tell Claude &quot;Launch explore agent with Sonnet 4.5&quot; if you want it to use Sonnet instead of Haiku (I found this by just trying things out but we will see how this happens)</p><p>The Explore agent is a read-only file search specialist. It can use Glob, Grep, Read, and limited Bash commands to navigate codebases but is strictly prohibited from creating or modifying files.</p><p>You will notice how thorough the prompt is in terms of specifying when to use what tool call. Well, most people underestimate how hard it&apos;s to make tool calling work accurately.</p><h5 level="5" id="Explore-agent-prompt">Explore agent prompt</h5><p>View full Explore agent prompt</p><p>This is the Explore agent prompt from 2.0.56 and it should be similar now too. <a target="_blank" rel="noopener noreferrer" href="https://github.com/Piebald-AI/claude-code-system-prompts/blob/main/system-prompts/agent-prompt-explore.md">Reference</a>. These are captured by intercepting requests. <a target="_blank" rel="noopener noreferrer" href="https://youtu.be/i0P56Pm1Q3U?si=LFO83flfYJpLGgMH">Reference video</a>.</p><h3 level="3" id="Do-sub-agents-inherit-the-context">Do sub-agents inherit the context?</h3><p>The <code>general-purpose</code> and <code>plan</code> sub-agents inherit the full context, while <code>Explore</code> starts with a fresh slate-which makes sense since search tasks are often independent. Many tasks involve searching through large amounts of code to filter for something relevant and the individual parts don&apos;t need prior conversation context.</p><p>If I am trying to understand a feature or just looking up simple things in the codebase, I let Claude do the Explore agent searches. Explore agent passes a summary back to the main agent and then Opus 4.5 will publish the results or may choose to go through each file itself. If it does not, I explicitly tell it to.</p><p><strong>It&apos;s important that the model goes through each of the relevant files itself so that all that ingested context can attend to each other.</strong> That&apos;s the high level idea of attention. Make context cross with previous context. This way model can extract more pair-wise relationships and therefore better reasoning and prediction. Explore agent returns summaries which can be lossy compression. When Opus 4.5 reads all relevant context itself, it knows what details are relevant to what context. This insight goes a long way even in production applications (but you only get it if someone tells you or you have read about self-attention mechanism).</p><p><strong>Codex does not have a concept of sub-agents</strong> and it&apos;s probably a conscious decision by the devs. GPT-5.2 has a 400K context window and according to benchmarks, it&apos;s long context retrieval capabilities are a massive improvement. Although people have tried making Codex use headless claude as sub-agents haha. You can just do things.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/18pm-1.webp" alt="Codex using Claude Haiku as sub-agent"><p>sub-agent shenanigans by Peter. <a target="_blank" rel="noopener noreferrer" href="https://x.com/steipete/status/1979602825224355999?s=20">source</a></p><h3 level="3" id="How-do-sub-agents-spawn">How do sub-agents spawn</h3><p>From the reverse engineered resources/leaked system prompt, it&apos;s possible to see that the sub-agents are spawned via the <code>Task tool</code>.</p><p><strong>Turns out you can ask Claude too</strong>. (I think the developers are allowing this now?). It&apos;s not a hallucination. The prompt pertaining to pre-defined tools are there in the system prompt and Claude code dynamically injects reminders/tools often to the ongoing context.</p><p>Try these set of prompts with Opus 4.5</p><ol><li><p>Tell me the <code>Task</code> tool description</p></li><li><p>Give me full description</p></li><li><p>Show me entire tool schema</p></li></ol><h4 level="4" id="Task-Tool-Prompt">Task Tool Prompt</h4><p>You will get the output something like below (click) but to summarise - It defines <strong>5 agent types</strong>: <code>general-purpose</code> (full tool access, inherits context), <code>Explore</code> (fast read-only codebase search), <code>Plan</code> (software architect for implementation planning), <code>claude-code-guide</code> (documentation lookup), and <code>statusline-setup</code>. Notice how each sub-agent is defined with its specific use case and available tools. Also notice the &quot;When NOT to use&quot; section - this kind of negative guidance helps the model avoid unnecessary sub-agent spawning for simple tasks.</p><p><strong>View full Task tool prompt</strong></p><h4 level="4" id="Task-Tool-Schema">Task Tool Schema</h4><p>I want you to focus on the tool schema. The Task tool prompt above is detailed guidance on <em>how</em> to use the tool that resides in the system prompt. The tool schema defines the tool or the function.</p><div class="llt-code readonly"><div class="language">bash</div><div class="wrapper"><pre><code>{
  <span class="hljs-string" class="hljs-string">&quot;<span class="hljs-variable" class="hljs-variable">$schema</span>&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;http://json-schema.org/draft-07/schema#&quot;</span>,
  <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;object&quot;</span>,
  <span class="hljs-string" class="hljs-string">&quot;additionalProperties&quot;</span>: <span class="hljs-literal" class="hljs-literal">false</span>,
  <span class="hljs-string" class="hljs-string">&quot;required&quot;</span>: [<span class="hljs-string" class="hljs-string">&quot;description&quot;</span>, <span class="hljs-string" class="hljs-string">&quot;prompt&quot;</span>, <span class="hljs-string" class="hljs-string">&quot;subagent_type&quot;</span>],
  <span class="hljs-string" class="hljs-string">&quot;properties&quot;</span>: {
    <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: {
      <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;string&quot;</span>,
      <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;A short (3-5 word) description of the task&quot;</span>
    },
    <span class="hljs-string" class="hljs-string">&quot;prompt&quot;</span>: {
      <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;string&quot;</span>,
      <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;The task for the agent to perform&quot;</span>
    },
    <span class="hljs-string" class="hljs-string">&quot;subagent_type&quot;</span>: {
      <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;string&quot;</span>,
      <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;The type of specialized agent to use for this task&quot;</span>
    },
    <span class="hljs-string" class="hljs-string">&quot;model&quot;</span>: {
      <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;string&quot;</span>,
      <span class="hljs-string" class="hljs-string">&quot;enum&quot;</span>: [<span class="hljs-string" class="hljs-string">&quot;sonnet&quot;</span>, <span class="hljs-string" class="hljs-string">&quot;opus&quot;</span>, <span class="hljs-string" class="hljs-string">&quot;haiku&quot;</span>],
      <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;Optional model to use for this agent. If not specified, inherits from parent. Prefer haiku for quick, straightforward tasks to minimize cost and latency.&quot;</span>
    },
    <span class="hljs-string" class="hljs-string">&quot;resume&quot;</span>: {
      <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;string&quot;</span>,
      <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;Optional agent ID to resume from. If provided, the agent continues from the previous execution transcript.&quot;</span>
    },
    <span class="hljs-string" class="hljs-string">&quot;run_in_background&quot;</span>: {
      <span class="hljs-string" class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;boolean&quot;</span>,
      <span class="hljs-string" class="hljs-string">&quot;description&quot;</span>: <span class="hljs-string" class="hljs-string">&quot;Set to true to run this agent in the background. Use TaskOutput to read the output later.&quot;</span>
    }
  }
}
</code></pre></div></div><p>The main agent calls the Task tool to spawn a sub-agent, using its reasoning to decide the parameters. Notice the <code>model</code> parameter - when I say &quot;Use Explore with Sonnet&quot;, the model makes the tool call with <code>model: &quot;sonnet&quot;</code>.</p><p>Till August&apos;25 or so, Claude Code used to show the Task tool performing actions in the TUI but now TUI shows the sub-agent name instead.</p><h4 level="4" id="Background-agent-useful-for-debugging-2060">Background agent useful for debugging (2.0.60)</h4><p>Notice the <code>run_in_background</code> parameter. It decides whether to send a sub-agent to run in the background. I like the background process feature - it is super helpful for debugging or just monitoring log outputs from process. Sometimes you have a long running python script that you wanna monitor etc.</p><p>Model usually automatically decides to put a process in background but you can explicitly tell it to do so. Note that &quot;Background Tasks&quot; is different. Using an <code>&amp;</code> sends a task to Claude Web (should have named it Claude Cloud haha). I am yet to get this to work properly.</p><h2 level="2" id="My-Workflow">My Workflow</h2><h3 level="3" id="Setup">Setup</h3><p>I have a pretty simplish/task based workflow: CC as the main driver, Codex for review and difficult tasks, and Cursor for reading code and manual edits. I rarely use Plan Mode. Instead, once requirements are clear enough, I explore the codebase to find the relevant files myself.</p><p>Edit: I have started trying out plan mode a bit more but I still prefer my current approach.</p><h3 level="3" id="Exploration-and-Execution">Exploration and Execution</h3><p>Opus 4.5 is amazing at explaining stuff and makes stellar ASCII diagrams. The May&apos;25 knowledge cutoff helps here too. So my exploration involves asking lots of questions-clarifying requirements, understanding where/how/why to make changes. It might be less efficient than Plan Mode, but I like this approach.</p><p>Once I have enough context, I spam /ultrathink and ask it what changes are required and then if things look ok, I start the execution closely monitoring the changes - basically micro-managing it. I sometimes ask Codex&apos;s second opinion here lol.</p><p>For difficult new features, I sometimes use a &quot;throw-away first draft&quot; approach. Once I understand what changes are needed, I create a new branch and let Claude write the feature end-to-end while I observe. I then compare its output against my mental model as to how close did it get to my requirements? Where did it diverge? This process reveals Claude&apos;s errors and the decisions/biases it made based on the context it had. With the benefit of this hindsight, I run another iteration, this time with sharper prompts informed by what I learned from the first pass. Kinda like Tenet.</p><p>For backend-heavy or just complex features specifically, I&apos;ll sometimes ask Codex xhigh to generate the plan instead.</p><h3 level="3" id="What-I-use-and-dont">What I use (and don&apos;t)</h3><p>I maintain a few custom commands, use CLAUDE.md and scratchpad extensively. No custom sub-agents. I use MCP sometimes if need shall arise (e.g for docs. I have tried Playwright and Figma MCP so far) but in general not a fan. I have used hooks for simple stuff in the past and need-basis. skills/plugins are something that I am yet to use more regularly. I often use background agents for observability (monitoring log / error) purposes. I rarely use git worktrees.</p><p>It&apos;s worth noting that <strong>the harness is so heavily engineered</strong> that Claude knows which sub-agent to spawn, what command/tool call/skill to run, what to run in async manner. It&apos;s able to heavy carry the agent loop that <strong>your task is mainly to use your judgement and prompt it in right direction</strong>. The next generation of models will get better and the relevant scaffolding will reduce for existing feature and increase for newer features. (Re: contrasting to Karpathy sensei&apos;s latest tweet shown at beginning)</p><p>It&apos;s not at all required to know the features in depth to be honest. <strong>However knowing how things work can help you steer the models better</strong> like telling the Explore agent to use Sonnet.</p><h3 level="3" id="Review">Review</h3><blockquote><p>getting claude opus 4.5 changes reviewed by gpt-5.1-codex-max high <a target="_blank" rel="noopener noreferrer" href="https://t.co/A4tYN3W3Q6">pic.twitter.com/A4tYN3W3Q6</a></p><p>â€” sankalp (@dejavucoder) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/dejavucoder/status/1996095775030608177?ref_src=twsrc%5Etfw">December 3, 2025</a></p></blockquote><p>For reviewing code and finding bugs, I find GPT-5.2-Codex to be superior. Just use <code>/review</code>. Better than code review products too.</p><p>It&apos;s able to find bugs and mention severity like P1, P2. It&apos;s less likely to report false-positives and more trustable when it comes to confusing changes as compared to Claude. This Claude for execution and GPT/o-series model for review/bugs dynamic has been pretty constant for me for probably a year.</p><p>âœ± Percolating...</p><h2 level="2" id="Intermission">Intermission</h2><p>&lt;system-reminder&gt;</p><p>Now is a good time to take a breath and refresh your context window. Before we get to the next set of features, it&apos;s worth going through context management fundamentals. Things might get a bit difficult for the technically-lite folks. Don&apos;t give up. Read through the post. Even ask Claude to explain stuff you don&apos;t understand.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/never_giveup.webp" alt="never give up"><p>&lt;/system-reminder&gt;</p><p>âœ± Cogitating...</p><h2 level="2" id="But-what-is-Context-Engineering">But what is Context Engineering</h2><h3 level="3" id="Agents-are-token-guzzlers">Agents are token guzzlers</h3><p>An agent in a harness can pro-actively do a lot of tool calls to read your codebase and other inputs, edit stuff, make writes etc. In this process, they can produce a lot of data which gets added to the running conversation i.e the context window. Anthropic refers to this art and science of curating what will go into the limited context window from this information as <strong>context engineering</strong>.</p><p>You may ask how are tool calls adding tokens to the context window? The flow works like this:</p><div class="llt-code readonly"><div class="language">yaml</div><div class="wrapper"><pre><code><span class="hljs-attr" class="hljs-attr">Context window:</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">User:</span> <span class="hljs-string" class="hljs-string">&quot;Make a landing page for my coffee shop&quot;</span>
<span class="hljs-string" class="hljs-string">â”‚</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> [<span class="hljs-attr" class="hljs-attr">tool_call:</span> <span class="hljs-string" class="hljs-string">web_search(&quot;modern</span> <span class="hljs-string" class="hljs-string">coffee</span> <span class="hljs-string" class="hljs-string">shop</span> <span class="hljs-string" class="hljs-string">landing</span> <span class="hljs-string" class="hljs-string">page</span> <span class="hljs-string" class="hljs-string">design&quot;)</span>]
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Tool result:</span> [<span class="hljs-number" class="hljs-number">10</span> <span class="hljs-string" class="hljs-string">results</span> <span class="hljs-string" class="hljs-string">with</span> <span class="hljs-string" class="hljs-string">snippets</span>, <span class="hljs-string" class="hljs-string">URLs</span>]           <span class="hljs-string" class="hljs-string">â†</span> <span class="hljs-string" class="hljs-string">~1.5K</span> <span class="hljs-string" class="hljs-string">tokens</span>
<span class="hljs-string" class="hljs-string">â”‚</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> [<span class="hljs-attr" class="hljs-attr">tool_call:</span> <span class="hljs-string" class="hljs-string">read_file(&quot;brand-guidelines.pdf&quot;)</span>]
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Tool result:</span> [<span class="hljs-string" class="hljs-string">extracted</span> <span class="hljs-string" class="hljs-string">text</span>, <span class="hljs-string" class="hljs-string">colors</span>, <span class="hljs-string" class="hljs-string">fonts</span>]  <span class="hljs-string" class="hljs-string">â†</span> <span class="hljs-string" class="hljs-string">~4K</span> <span class="hljs-string" class="hljs-string">tokens</span>
<span class="hljs-string" class="hljs-string">â”‚</span>  <span class="hljs-string" class="hljs-string">(must</span> <span class="hljs-string" class="hljs-string">be</span> <span class="hljs-string" class="hljs-string">here,</span> <span class="hljs-string" class="hljs-string">model</span> <span class="hljs-string" class="hljs-string">is</span> <span class="hljs-string" class="hljs-string">stateless)</span>
<span class="hljs-string" class="hljs-string">â”‚</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> <span class="hljs-string" class="hljs-string">&quot;I&apos;ll create a warm, minimal design using your brand colors...&quot;</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> [<span class="hljs-attr" class="hljs-attr">tool_call:</span> <span class="hljs-string" class="hljs-string">create_file(&quot;landing-page.html&quot;)</span>]
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Tool result:</span> [<span class="hljs-string" class="hljs-string">success</span>, <span class="hljs-number" class="hljs-number">140</span> <span class="hljs-string" class="hljs-string">lines</span>]                       <span class="hljs-string" class="hljs-string">â†</span> <span class="hljs-string" class="hljs-string">~50</span> <span class="hljs-string" class="hljs-string">tokens</span>
<span class="hljs-string" class="hljs-string">â”‚</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> [<span class="hljs-attr" class="hljs-attr">tool_call:</span> <span class="hljs-string" class="hljs-string">generate_image(&quot;cozy</span> <span class="hljs-string" class="hljs-string">coffee</span> <span class="hljs-string" class="hljs-string">shop</span> <span class="hljs-string" class="hljs-string">interior&quot;)</span>]
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Tool result:</span> [<span class="hljs-string" class="hljs-string">image</span> <span class="hljs-string" class="hljs-string">URL</span> <span class="hljs-string" class="hljs-string">returned</span>]                       <span class="hljs-string" class="hljs-string">â†</span> <span class="hljs-string" class="hljs-string">~30</span> <span class="hljs-string" class="hljs-string">tokens</span>
<span class="hljs-string" class="hljs-string">â”‚</span>
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> [<span class="hljs-attr" class="hljs-attr">tool_call:</span> <span class="hljs-string" class="hljs-string">edit_file(&quot;landing-page.html&quot;)</span>]
<span class="hljs-string" class="hljs-string">â”œâ”€</span> <span class="hljs-attr" class="hljs-attr">Tool result:</span> [<span class="hljs-attr" class="hljs-attr">diff:</span> <span class="hljs-string" class="hljs-string">added</span> <span class="hljs-string" class="hljs-string">hero</span> <span class="hljs-string" class="hljs-string">image</span> <span class="hljs-string" class="hljs-string">+</span> <span class="hljs-string" class="hljs-string">menu</span> <span class="hljs-string" class="hljs-string">section</span>]    <span class="hljs-string" class="hljs-string">â†</span> <span class="hljs-string" class="hljs-string">~300</span> <span class="hljs-string" class="hljs-string">tokens</span>
<span class="hljs-string" class="hljs-string">â”‚</span>
<span class="hljs-string" class="hljs-string">â””â”€</span> <span class="hljs-attr" class="hljs-attr">Assistant:</span> <span class="hljs-string" class="hljs-string">&quot;Done! Here&apos;s your landing page with hero, menu, and contact sections.&quot;</span>

<span class="hljs-attr" class="hljs-attr">Total:</span> <span class="hljs-string" class="hljs-string">~6K+</span> <span class="hljs-string" class="hljs-string">tokens</span> <span class="hljs-string" class="hljs-string">for</span> <span class="hljs-string" class="hljs-string">one</span> <span class="hljs-string" class="hljs-string">task.</span> <span class="hljs-string" class="hljs-string">Everything</span> <span class="hljs-string" class="hljs-string">stays</span> <span class="hljs-string" class="hljs-string">in</span> <span class="hljs-string" class="hljs-string">context.</span>
</code></pre></div></div><p>The key thing to note here is that <strong>both the tool call and the tool call outputs are added to the context</strong> so that the LLM can know the results. This is because <strong>LLMs are stateless</strong> - they don&apos;t have memory outside the context window. Let&apos;s say you have n messages in a conversation. When you send the next message, the request will again process n + 1 messages in the LLM ~ single context window.</p><p>If you don&apos;t add information about the chosen tool call was, LLM won&apos;t know and if you don&apos;t plug the output, then it won&apos;t know the outcome. <strong>The tool call results can quickly fill your context</strong> and this is why agents can get super expensive too.</p><h3 level="3" id="Context-engineering">Context engineering</h3><p>I quote directly from <a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">effective-context-engineering-for-ai-agents</a></p><blockquote><p>Context refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context - in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.</p><p><strong>Context engineering is about answering &quot;what configuration of context is most likely to generate our model&apos;s desired behavior?&quot;</strong></p></blockquote><p>Everything we have discussed so far comes under context engineering. Sub-agents, using a scratchpad, compaction are obvious examples of context management methods used in Claude Code.</p><h4 level="4" id="Context-rotdegradation">Context rot/degradation</h4><p>Limited context window - The context retrieval performance of LLMs degrades as every new token is introduced. To paraphrase the above blog - think of context as a limited &quot;attention budget&quot;. This is a consequence of the attention mechanism itself as it gets harder to model the pairwise relationships - think of it like getting harder to focus on things far apart.</p><p>GPT-5.2 has a context window of 400K input tokens. Opus 4.5 has 200K. Gemini 3 Pro has a 1M context window length. Now the effectiveness of these context windows can vary too, just the length doesn&apos;t matter. That said if you want to ask something from a 900K long input, you would be able to most reliably do that only with Gemini 3 Pro.</p><p><a target="_blank" rel="noopener noreferrer" href="https://research.trychroma.com/context-rot">Chroma&apos;s context rot article</a> goes deep into some experiments which showed performance drops with length and not task difficulty.</p><p>A rough corollary one can draw is effective context windows are probably 50-60% or even lesser. Don&apos;t start a complicated task when you are half-way in the conversation. Do compaction or start a new one.</p><p>Everything being done in prompts and code we have seen so far has been to -</p><ul><li><p>Plug the most relevant context</p></li><li><p>Reduce context bloat / irrelevant context</p></li><li><p>Have few and non-conflicting instructions to make it easier for models to follow</p></li><li><p>Make tool calls work better via reminders and run-time injections</p></li></ul><p>The next few sections showcase features and implementation that are designed for better context management and agentic performance.</p><h3 level="3" id="MCP-server-and-code-execution">MCP server and code execution</h3><p>MCP servers aren&apos;t my go-to, but worth covering. MCP servers are servers that can be hosted on your machine or remotely on the internet. These may expose filesystem, tools and integrations like CRM, Google Drive etc. They are essentially a way for models to connect to external tools and services.</p><p>In order to connect to MCP server, you need a host (Claude) which can house the MCP client. The MCP client can invoke the protocol to connect. Once connected, the MCP client exposes tools, resources, prompts provided by server.</p><p><strong>The tool definitions are loaded upfront into the context window</strong> of host, bloating it.</p><h4 level="4" id="Code-execution-with-MCP">Code execution with MCP</h4><p>I like the idea of Code Execution with MCP even though it&apos;s propaganda for more token consumption.</p><p>Quoting <a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/code-execution-with-mcp">Code execution with MCP</a>:</p><blockquote><p>As MCP usage scales, there are two common patterns that can increase agent cost and latency:</p><ul><li><p>Tool definitions overload the context window;</p></li><li><p>Intermediate tool results consume additional tokens.</p></li></ul></blockquote><p>More MCP servers means more tool definitions bloating the context.</p><p>MCP Code exec suggests instead of direct tool calls, <strong>expose code APIs rather than tool call definitions</strong> and give Claude a sandbox execution environment with a filesystem. Then let it write code to make the tool calls. It is an elegant idea and is pretty similar to skills in the sense it&apos;s &quot;prompt on demand&quot;.</p><h3 level="3" id="What-are-the-system-reminders-in-Claude-prompts">What are the system-reminders in Claude prompts</h3><p>One technique to combat context degradation is to repeatedly inject objectives into the context. Manus shared their approach in their <a target="_blank" rel="noopener noreferrer" href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus">Context Engineering blog</a>:</p><blockquote><p><strong>Manipulate Attention Through Recitation</strong></p><p>If you&apos;ve worked with Manus, you&apos;ve probably noticed something curious: when handling complex tasks, it tends to create a todo.md file-and update it step-by-step as the task progresses, checking off completed items.</p><p>That&apos;s not just cute behavior-<strong>it&apos;s a deliberate mechanism to manipulate attention</strong>.</p><p>A typical task in Manus requires around 50 tool calls on average. That&apos;s a long loop-and since Manus relies on LLMs for decision-making, it&apos;s vulnerable to drifting off-topic or forgetting earlier goals, especially in long contexts or complicated tasks.</p><p>By constantly rewriting the todo list, Manus is <strong>reciting its objectives into the end of the context</strong>. This pushes the global plan into the model&apos;s recent attention span, <strong>avoiding &quot;lost-in-the-middle&quot; issues</strong> and reducing goal misalignment. In effect, it&apos;s using natural language to bias its own focus toward the task objective-without needing special architectural changes.</p></blockquote><p>Claude Code has todo lists too. Now you know part of the logic for it. They act like reminders. Both todo list and plan are stored as markdown file and they are persisted during compaction. So they are used to preserve state as well.</p><p>Claude Code also tries something similar via plugging reminder tags into user messages and tool results. Some of them are mentioned in tool descriptions, other reminders are added at runtime via code.</p><p>I asked Claude about what system reminders are present in the system prompt.</p><div class="llt-code readonly"><div class="language">vbnet</div><div class="wrapper"><pre><code>&gt; <span class="hljs-keyword" class="hljs-keyword">Me</span> <span class="hljs-keyword" class="hljs-keyword">to</span> Claude: Tell <span class="hljs-keyword" class="hljs-keyword">me</span> what system reminders <span class="hljs-keyword" class="hljs-keyword">do</span> you have <span class="hljs-keyword" class="hljs-keyword">in</span> your prompt. show <span class="hljs-keyword" class="hljs-keyword">me</span> the exact thing. show <span class="hljs-keyword" class="hljs-keyword">me</span> the tags <span class="hljs-keyword" class="hljs-keyword">as</span> well.
tell <span class="hljs-keyword" class="hljs-keyword">me</span> what places they are added. redact my CLAUDE MD ultrathink give a compact output please

âº Here<span class="hljs-comment" class="hljs-comment">&apos;s what I can see:</span>

  System Reminder Locations

  <span class="hljs-number" class="hljs-number">1</span>. <span class="hljs-keyword" class="hljs-keyword">In</span> user messages (<span class="hljs-built_in" class="hljs-built_in">like</span> yours just now):
  &lt;system-reminder&gt;
  <span class="hljs-keyword" class="hljs-keyword">As</span> you answer the user<span class="hljs-comment" class="hljs-comment">&apos;s questions, you can use the following context:</span>
  # claudeMd
  Codebase <span class="hljs-built_in" class="hljs-built_in">and</span> user instructions are shown below...

  Contents <span class="hljs-keyword" class="hljs-keyword">of</span> /Users/sankalp/.claude/CLAUDE.md (user<span class="hljs-comment" class="hljs-comment">&apos;s private global instructions for all projects):</span>
  [REDACTED - your personal CLAUDE.md]
  &lt;/system-reminder&gt;

  <span class="hljs-number" class="hljs-number">2</span>. Referenced <span class="hljs-keyword" class="hljs-keyword">in</span> my instructions:
  <span class="hljs-string" class="hljs-string">&quot;Tool results and user messages may include &lt;system-reminder&gt; tags. &lt;system-reminder&gt; tags contain useful
  information and reminders. They are automatically added by the system, and bear no direct relation to the
  specific tool results or user messages in which they appear.&quot;</span>
</code></pre></div></div><p>For reference, an older version of CC 2.0.56 used to have this detailed reminder <a target="_blank" rel="noopener noreferrer" href="https://github.com/Piebald-AI/claude-code-system-prompts/blob/main/system-prompts/system-reminder-plan-mode-is-active.md">system-reminder-plan-mode-is-active</a>.</p><p>I think <a target="_blank" rel="noopener noreferrer" href="https://x.com/mitsuhiko">Armin</a> talks about this in his post <a target="_blank" rel="noopener noreferrer" href="https://lucumr.pocoo.org/2025/12/17/what-is-plan-mode/">What Actually Is Claude Codeâ€™s Plan Mode?</a> when he refers to <code>recurring prompts to remind the agent</code>.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/48am.webp" alt="Plan mode"><p>Armin&apos;s Plan Mode explanation</p><p>If you look at the leaked prompts, you will notice there are like 2-3 prompts for plan mode and 2-3 tool schemas like ENTRY_PLAN_MODE_TOOL, <a target="_blank" rel="noopener noreferrer" href="https://github.com/Piebald-AI/claude-code-system-prompts/blob/main/system-prompts/tool-description-exitplanmode.md">EXIT_PLAN_MODE_TOOL</a>. The latter would write down the output into a markdown file which you can access via /plan. Everything is a markdown.</p><h3 level="3" id="Skills-and-Plugins">Skills and Plugins</h3><p>Anthropic introduced <a target="_blank" rel="noopener noreferrer" href="https://code.claude.com/docs/en/skills">Agent Skills</a> recently and these got recently adopted by Codex too. A skill is a folder containing a SKILL.md file, other referenceable files and code scripts that do some user-defined task.</p><p>The SKILL.md contains some meta-data via which LLM can know what skills are available (meta-data is added to system prompt) If Claude feels the skill is relevant, it will perform a tool call to read the contents of skill and download the domain expertise just like Neo in Matrix 1999. The code scripts may contain tools that Claude can use.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/download.webp" alt="Neo downloading skills in The Matrix"><p>&quot;I know Kung Fu&quot; - Skills load on-demand, just like Neo in The Matrix (1999)</p><p>Normally, to teach domain expertise, you would need to write all that info in system prompt and probably even tool call definitions. With skills, you don&apos;t have to do that as the model loads it on-demand. This is especially useful when you are not sure if you require those instructions always.</p><h4 level="4" id="Plugins">Plugins</h4><p>Plugins are a packaging mechanism that bundles skills, slash commands, sub-agents, hooks, and MCP servers into a single distributable unit. They can be installed via <code>/plugins</code> and are namespaced to avoid conflicts (e.g., <code>/my-plugin:hello</code>). While standalone configs in <code>.claude/</code> are great for personal/project-specific use, plugins make it easy to share functionality across projects and teams.</p><p>The popular <code>frontend-design</code> plugin is actually just a skill. (<a target="_blank" rel="noopener noreferrer" href="https://github.com/anthropics/claude-code/blob/main/plugins/frontend-design/skills/frontend-design/SKILL.md">source</a>)</p><p>View frontend-design skill prompt</p><h3 level="3" id="Hooks">Hooks</h3><p>Hooks are available in Claude Code and Cursor (Codex is yet to implement). They allow you to observe when a certain stage in the agent loop lifecycle starts or ends and let you run bash scripts before or after to make changes to the agent loop.</p><p>There are hooks like <code>Stop</code>, <code>UserPromptSubmit</code> etc. For instance <code>Stop</code> hook runs after Claude finishes responding and the <code>UserPromptSubmit</code> hook runs when user submits a prompt before Claude processes it.</p><p>The first hook I created was to play an anime notification sound when Claude stopped responding. I was obviously inspired by Cursor&apos;s notification sound.</p><p>One funny use case to run Claude for hours might be running a &quot;Do more&quot; prompt when Claude finishes current task via the <code>Stop</code> hook.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/50am.webp" alt="Do more hook example"><p>&quot;Do more&quot; prompt via Stop hook to keep Claude running. <a target="_blank" rel="noopener noreferrer" href="https://x.com/msfeldstein/status/1990178454659268828">source</a></p><h3 level="3" id="Combining-Hooks-Skills-and-Reminders">Combining Hooks, Skills and Reminders</h3><p>I came across this post during my research for this blog post. This person beautifully combined the concepts and features we discussed so far. They use hooks to remind the model about the skill. If the utility/requirement arises, there&apos;s a lot of space for customization. You might not need such heavy customization but can at least take inspiration. (Speaking for myself lol)</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/11am.webp" alt="Combining hooks, skills and reminders"><p>Source: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/ClaudeCode/comments/1oivs81/claude_code_is_a_beast_tips_from_6_months_of/">Claude Code is a beast - tips from 6 months of usage</a></p><p>Anthropic recommends to keep skill.md under 500 lines so they divided it into separate files and combined with hooks and reduced the size of their CLAUDE.md.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/23am.webp" alt="Reduced CLAUDE.md with skills"><p>Dividing instructions into skill files to reduce CLAUDE.md size. Source: <a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/ClaudeCode/comments/1oivs81/claude_code_is_a_beast_tips_from_6_months_of/">same post</a></p><p>âœ± Coalescing...</p><h2 level="2" id="Conclusion">Conclusion</h2><p>Hopefully you learnt a bunch of things from this super long post and will apply the learnings not only in CC but other tools as well. I feel a bit weird writing this but we are going through some transformative times. There are already moments when I almost feel like a background agent and then other times when I feel smart when the models couldn&apos;t solve a particular bug.</p><blockquote><p>claude and codex to me when i realise i am the background agent <a target="_blank" rel="noopener noreferrer" href="https://t.co/wkihYFQmQM">pic.twitter.com/wkihYFQmQM</a></p><p>â€” sankalp (@dejavucoder) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/dejavucoder/status/2001267688916852910?ref_src=twsrc%5Etfw">December 17, 2025</a></p></blockquote><p>I no longer look forward to new releases because they just keep happening anyways (shoutout to OpenAI). Deepseek and Kimi K3 are in the queue.</p><p>I am expecting improvements in RL training, long context effectiveness via maybe new attention architectures, higher throughput models, lesser hallucination models. There might be a o1/o3 level reasoning breakthrough or maybe something in continual learning in 2026. I look forward to these but at the same time I find it scary because more significant capability unlock will make the world unpredictable haha.</p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/dario-2.webp" alt="Dario Amodei"><p>Dario with mandate of heaven for now</p><p>If you found this useful, try one new feature from this post today. Happy building!</p><p><strong>Thanks for reading. Please like/share/RT the post if you liked it.</strong></p><hr><p>Future Edits:</p><p>Boris Cherney recently shared his workflow</p><blockquote><p>I&apos;m Boris and I created Claude Code. Lots of people have asked how I use Claude Code, so I wanted to show off my setup a bit.<br><br>My setup might be surprisingly vanilla! Claude Code works great out of the box, so I personally don&apos;t customize it much. There is no one correct way toâ€¦</p><p>â€” Boris Cherny (@bcherny) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/bcherny/status/2007179832300581177?ref_src=twsrc%5Etfw">January 2, 2026</a></p></blockquote><p>If you understood this post, you would be able to fully understand what Thariq&apos;s prompt does in here. This got lot of traction on the timeline.</p><blockquote><p>my favorite way to use Claude Code to build large features is spec based<br><br>start with a minimal spec or prompt and ask Claude to interview you using the AskUserQuestionTool<br><br>then make a new session to execute the spec <a target="_blank" rel="noopener noreferrer" href="https://t.co/Lwejskje4a">pic.twitter.com/Lwejskje4a</a></p><p>â€” Thariq (@trq212) <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/trq212/status/2005315275026260309?ref_src=twsrc%5Etfw">December 28, 2025</a></p></blockquote><h2 level="2" id="Acknowledgements">Acknowledgements</h2><p>Thanks to <a target="_blank" rel="noopener noreferrer" href="https://x.com/tokenbender">tokenbender</a>, <a target="_blank" rel="noopener noreferrer" href="https://x.com/twofifteenam">telt</a>, <a target="_blank" rel="noopener noreferrer" href="https://x.com/DebadreeC">debadree</a>, <a target="_blank" rel="noopener noreferrer" href="https://x.com/Matthewagi">matt</a>, <a target="_blank" rel="noopener noreferrer" href="https://x.com/thepushkarp">pushkar</a> for showing the courage to read the final draft.</p><p>Thanks to Claude Opus 4.5 for editing and all the Twitter people who have been quoted in this post.</p><hr><h2 level="2" id="References">References</h2><h3 level="3" id="My-Previous-Posts">My Previous Posts</h3><ul><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/my-claude-code-experience-after-2-weeks-of-usage/">My Experience With Claude Code After 2 Weeks of Adventures</a> - July 2025</p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://sankalp.bearblog.dev/how-prompt-caching-works/">How Prompt Caching Works</a> - Technical deep dive</p></li></ul><h3 level="3" id="Anthropic-Engineering-Blog">Anthropic Engineering Blog</h3><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/building-effective-agents">Building Effective Agents</a> - Agent architecture fundamentals</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">Effective Context Engineering for AI Agents</a> - Context management guide</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://www.anthropic.com/engineering/code-execution-with-mcp">Code Execution with MCP</a> - MCP patterns</p></li></ul><h3 level="3" id="Claude-Code-Documentation">Claude Code Documentation</h3><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md">Claude Code Changelog</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://code.claude.com/docs/en/checkpointing">Checkpointing</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://code.claude.com/docs/en/skills">Agent Skills</a></p></li></ul><h3 level="3" id="Research--Technical-Resources">Research &amp; Technical Resources</h3><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://research.trychroma.com/context-rot">Context Rot</a> - Research on context degradation</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://cursor.com/learn/tool-calling">Tool Calling Explained</a> - Cursor&apos;s guide</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://lucumr.pocoo.org/2025/12/17/what-is-plan-mode/">What Actually Is Claude Code&apos;s Plan Mode?</a> - Armin Ronacher&apos;s analysis</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus">Context Engineering for AI Agents: Lessons from Building Manus</a></p></li></ul><h3 level="3" id="System-Prompts--Internals">System Prompts &amp; Internals</h3><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/Piebald-AI/claude-code-system-prompts">Claude Code System Prompts</a> - Reverse engineered prompts</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://youtu.be/i0P56Pm1Q3U?si=LFO83flfYJpLGgMH">System Prompt Extraction Video</a></p></li></ul><h3 level="3" id="Community-Resources">Community Resources</h3><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/hesreallyhim/awesome-claude-code">awesome-claude-code</a> - Commands, hooks, skills collection</p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/ClaudeCode/comments/1oivs81/claude_code_is_a_beast_tips_from_6_months_of/">Claude Code is a beast - tips from 6 months of usage</a> - Reddit post on hooks/skills combo</p></li></ul><h3 level="3" id="TwitterX-Discussions">Twitter/X Discussions</h3><ul><li><p><a target="_blank" rel="noopener noreferrer" href="https://x.com/karpathy/status/2004607146781278521">Karpathy on keeping up</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://x.com/addyosmani/status/2004663973912932625">Addy Osmani&apos;s take</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://x.com/bcherny/status/2004626064187031831">Boris (bcherny) on domain knowledge</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://x.com/trq212/status/2004575715472388278">Thariq&apos;s async agent use case</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://x.com/claudeai/status/2001010062769434785">Prompt suggestions announcement</a></p></li><li><p><a target="_blank" rel="noopener noreferrer" href="https://x.com/steipete/status/1979602825224355999">Peter&apos;s sub-agent shenanigans</a> | <a target="_blank" rel="noopener noreferrer" href="https://x.com/steipete/status/1982642868599804170">Part 2</a></p></li></ul><p></p><script type="module">const injectHtml = (root, html) => {
  const iframe = document.createElement("iframe");
  const htmlContent = `<html><head></head><body>${html}</body></html>`;
  iframe.style.width = "100%";
  iframe.style.height = "100%";
  iframe.onload = () => {
    const doc = iframe.contentDocument || iframe.contentWindow?.document;
    if (!doc) {
      return;
    }
    doc.open();
    doc.write(htmlContent);
    doc.close();
  };
  root.replaceChildren(iframe);
}
  document.querySelectorAll('.playground')?.forEach(el=>{
    const html = el.getAttribute('data-html');
    if (html) {
      injectHtml(el,html);
    }
    const indicator = document.createElement("div");
    indicator.className = "indicator";
    const showCode = document.createElement("div");
    showCode.className = "show-code";
    showCode.innerText = "code";
    showCode.onclick = () => {
      el.parentElement.classList.remove("preview-only");
    };
    const showPreview = document.createElement("div");
    showPreview.className = "show-preview";
    showPreview.innerText = "preview";
    showPreview.onclick = () => {
      el.parentElement.classList.add("preview-only");
    };
    indicator.appendChild(showCode);
    indicator.appendChild(showPreview);
    el.parentElement.appendChild(indicator);
    if (window.screen.width < 768) {
      showPreview.click();
    }
  });</script></div> <div data-page-id="A-Guide-to-Claude-Code-20-and-getting-better-at-using-coding-agents" class="navigator flex justify-between items-center mt-4 py-4"> <a href="/post/httpshelpobsidianmdcli" class="flex items-center gap-1 text-blue cursor-pointer flex-[45%]"> <div class="i-ri:arrow-left-double-line w-5 h-5 flex-shrink-0"></div> <div class="text-start">https://help.obsidian.md/cli</div> </a> <div></div> </div> </div> <div class="outline-wrapper"></div> </main>  <footer class="site-footer" data-astro-cid-sz7xmlte> <!-- å¯¼èˆªé“¾æŽ¥ --> <nav class="footer-nav" data-astro-cid-sz7xmlte>  <a href="/" class="footer-link" data-astro-cid-sz7xmlte> Home </a> <span class="nav-dot" data-astro-cid-sz7xmlte>Â·</span> <a href="/tag/projects" class="footer-link" data-astro-cid-sz7xmlte> Projects </a> <span class="nav-dot" data-astro-cid-sz7xmlte>Â·</span> <a href="/tools" class="footer-link" data-astro-cid-sz7xmlte> Notes </a> <span class="nav-dot" data-astro-cid-sz7xmlte>Â·</span> <a href="https://web.chatboxai.app/" class="footer-link" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> Chatbox </a> <span class="nav-dot" data-astro-cid-sz7xmlte>Â·</span> <a href="/about" class="footer-link" data-astro-cid-sz7xmlte> About </a>  </nav> <!-- åˆ†å‰²çº¿ --> <div class="footer-divider" data-astro-cid-sz7xmlte></div> <!-- ç‰ˆæƒä¿¡æ¯ --> <div class="footer-copyright" data-astro-cid-sz7xmlte> <a href="https://2kindlebox.github.io" data-astro-cid-sz7xmlte>Â©  2kindlebox  Â·  since 2026    Â·</a> <a href="/rss.xml" class="rss-link" target="_blank" rel="noopener noreferrer" title="RSS Feed" data-astro-cid-sz7xmlte> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 256 256" aria-label="RSS Feed" data-astro-cid-sz7xmlte> <rect width="256" height="256" rx="28" fill="#ff6b35" data-astro-cid-sz7xmlte></rect> <circle cx="68" cy="189" r="24" fill="#fff" data-astro-cid-sz7xmlte></circle> <path d="M160 213h-34a82 82 0 0 0-82-82v-34a116 116 0 0 1 116 116z" fill="#fff" data-astro-cid-sz7xmlte></path> <path d="M184 213A140 140 0 0 0 44 73V38a175 175 0 0 1 175 175z" fill="#fff" data-astro-cid-sz7xmlte></path> </svg> </a> </div> </footer>  <!-- â˜… æ·»åŠ å›žåˆ°é¡¶éƒ¨æŒ‰é’®ç»„ä»¶ --> <button id="back-to-top" class="back-to-top" aria-label="Back to top" data-astro-cid-wlspcwf4> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-wlspcwf4> <path d="M18 15l-6-6-6 6" data-astro-cid-wlspcwf4></path> </svg> </button>   </body></html>